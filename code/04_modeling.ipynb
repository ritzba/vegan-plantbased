{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d032a7",
   "metadata": {},
   "source": [
    "#  04 - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33e5ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a937265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Read vectorized data\n",
    "\n",
    "X_train = pd.read_csv('../data/X_train_tvec.csv')\n",
    "X_test = pd.read_csv('../data/X_test_tvec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76899248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Read target data \n",
    "\n",
    "y_train = pd.read_csv('../data/y_train.csv')\n",
    "y_test = pd.read_csv('../data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3383f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Reshape targets into vectors\n",
    "\n",
    "y_train = y_train.values.reshape(len(y_train),)\n",
    "y_test = y_test.values.reshape(len(y_test),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8be1f10c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27291, 2000), (9097, 2000), (27291,), (9097,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Check shapes\n",
    "\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e963dd1",
   "metadata": {},
   "source": [
    "##  Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f409fcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.720677146311971"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc6ba3a",
   "metadata": {},
   "source": [
    "A baseline model predicting the most common class (vegan/target = 0) will be correct approximately 72 % of the time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384acfad",
   "metadata": {},
   "source": [
    "##  Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "16ded05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dictionary of models and their params for GridSearch\n",
    "#  Patterned after a dictionary format designed by Chris Joyce\n",
    "\n",
    "model_dict = {\n",
    "    'logr':\n",
    "    {'model':\n",
    "     ('logr', LogisticRegression()),\n",
    "     'params':\n",
    "     {\"C\": np.logspace(-5,5,num = 10)}},\n",
    "    \n",
    "    'mnb':\n",
    "    {'model':\n",
    "     ('mnb', MultinomialNB()),\n",
    "     'params':\n",
    "     {\"alpha\": np.linspace(0,1,num = 10)}},\n",
    "    \n",
    "    'gnb':\n",
    "    {'model':\n",
    "     ('gnb', GaussianNB()),\n",
    "     'params':\n",
    "     {\"var_smoothing\": np.logspace(1e-6,1e-9,num = 10)}},\n",
    "    \n",
    "    'bnb':\n",
    "    {'model':\n",
    "     ('bnb', BernoulliNB()),\n",
    "     'params':\n",
    "     {\"alpha\": np.linspace(0,1,num = 10)}},\n",
    "        \n",
    "    'knn':\n",
    "    {'model':\n",
    "     ('knn', KNeighborsClassifier()),\n",
    "     'params':\n",
    "     {\"n_neighbors\": [3,5,7,10,15]}},\n",
    "        \n",
    "    'dt':\n",
    "    {'model':\n",
    "     ('dt', DecisionTreeClassifier()),\n",
    "     'params':\n",
    "     {\"max_depth\": [3,5,7,10],\n",
    "     \"min_samples_leaf\": [1,3,5]}},\n",
    "\n",
    "    'rf':\n",
    "    {'model':\n",
    "     ('rf', RandomForestClassifier()),\n",
    "     'params':\n",
    "     {\"n_estimators\": [30,50,100,200],\n",
    "     \"max_depth\": [3,5,7,10]}},\n",
    "    \n",
    "    'abc':\n",
    "    {'model':\n",
    "     ('abc', AdaBoostClassifier()),\n",
    "     'params':\n",
    "     {\"n_estimators\": [30,50,100,200],\n",
    "     }}\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16d3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dictionary to house best estimators and params\n",
    "best_models = {}\n",
    "\n",
    "# loop through models and their params\n",
    "for key, value in model_dict.items():\n",
    "    gs = GridSearchCV(value['model'][1], # classifier name\n",
    "                  value['params'], # parameters\n",
    "                      cv=5,\n",
    "                      verbose = 2, # view status during grid fit\n",
    "                      n_jobs=-1) # apply all available processor cores\n",
    "    \n",
    "    # fit the current iteration of GridSearchCV\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    # save best model and best params for scoring \n",
    "    best_models[key] = {'model': gs.best_estimator_,\n",
    "                        'params': gs.best_params_}\n",
    "    print(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec6643a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create list to store model scores\n",
    "model_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bee7f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Fit and score models\n",
    "logr = LogisticRegression(C = 0.2782559402207126)\n",
    "logr.fit(X_train, y_train)\n",
    "model_scores.append(['logr',logr.score(X_train,y_train),\\\n",
    "                   logr.score(X_test,y_test),\\\n",
    "                    cross_val_score(logr,X_test,y_test,cv=5).mean()])\n",
    "\n",
    "#  Write preds and pred probabilities to preds folder\n",
    "pd.DataFrame(logr.predict(X_test)).to_csv('../preds/logr.csv',index=False)\n",
    "pd.DataFrame(logr.predict_proba(X_test)).to_csv('../preds/logr_proba.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02d95ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(alpha = 1)\n",
    "mnb.fit(X_train, y_train)\n",
    "model_scores.append(['mnb',mnb.score(X_train,y_train),\\\n",
    "                   mnb.score(X_test,y_test),\\\n",
    "                    cross_val_score(mnb,X_test,y_test,cv=5).mean()])\n",
    "\n",
    "pd.DataFrame(mnb.predict(X_test)).to_csv('../preds/mnb.csv',index=False)\n",
    "pd.DataFrame(mnb.predict_proba(X_test)).to_csv('../preds/mnb_proba.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32f419e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB(var_smoothing = 1.000002302587744)\n",
    "gnb.fit(X_train, y_train)\n",
    "model_scores.append(['gnb',gnb.score(X_train,y_train),\\\n",
    "                   gnb.score(X_test,y_test),\\\n",
    "                    cross_val_score(gnb,X_test,y_test,cv=5).mean()])\n",
    "\n",
    "pd.DataFrame(gnb.predict(X_test)).to_csv('../preds/gnb.csv',index=False)\n",
    "pd.DataFrame(gnb.predict_proba(X_test)).to_csv('../preds/gnb_proba.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8afe5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB(alpha = 0.7777777777777777)\n",
    "bnb.fit(X_train, y_train)\n",
    "model_scores.append(['bnb',bnb.score(X_train,y_train),\\\n",
    "                   bnb.score(X_test,y_test),\\\n",
    "                    cross_val_score(bnb,X_test,y_test,cv=5).mean()])\n",
    "\n",
    "pd.DataFrame(bnb.predict(X_test)).to_csv('../preds/bnb.csv',index=False)\n",
    "pd.DataFrame(bnb.predict_proba(X_test)).to_csv('../preds/bnb_proba.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e51356a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train, y_train)\n",
    "model_scores.append(['knn',knn.score(X_train,y_train),\\\n",
    "                   knn.score(X_test,y_test),\\\n",
    "                    cross_val_score(knn,X_test,y_test,cv=5).mean()])\n",
    "\n",
    "pd.DataFrame(knn.predict(X_test)).to_csv('../preds/knn.csv',index=False)\n",
    "pd.DataFrame(knn.predict_proba(X_test)).to_csv('../preds/knn_proba.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b1cb10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 10, min_samples_leaf = 3)\n",
    "dt.fit(X_train, y_train)\n",
    "model_scores.append(['dt',dt.score(X_train,y_train),\\\n",
    "                   dt.score(X_test,y_test),\\\n",
    "                    cross_val_score(dt,X_test,y_test,cv=5).mean()])\n",
    "\n",
    "pd.DataFrame(dt.predict(X_test)).to_csv('../preds/dt.csv',index=False)\n",
    "pd.DataFrame(dt.predict_proba(X_test)).to_csv('../preds/dt_proba.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88632241",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 10, n_estimators = 50)\n",
    "rf.fit(X_train, y_train)\n",
    "model_scores.append(['rf',rf.score(X_train,y_train),\\\n",
    "                     rf.score(X_test,y_test),\\\n",
    "                    cross_val_score(rf,X_test,y_test,cv=5).mean()])\n",
    "\n",
    "pd.DataFrame(rf.predict(X_test)).to_csv('../preds/rf.csv',index=False)\n",
    "pd.DataFrame(rf.predict_proba(X_test)).to_csv('../preds/rf_proba.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "350ba5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(n_estimators = 200)\n",
    "abc.fit(X_train, y_train)\n",
    "model_scores.append(['abc',abc.score(X_train,y_train),\\\n",
    "                     abc.score(X_test,y_test),\\\n",
    "                    cross_val_score(abc,X_test,y_test,cv=5).mean()])\n",
    "\n",
    "pd.DataFrame(abc.predict(X_test)).to_csv('../preds/abc.csv',index=False)\n",
    "pd.DataFrame(abc.predict_proba(X_test)).to_csv('../preds/abc_proba.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "425a7d25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['logr', 0.9076252244329632, 0.8938111465318237, 0.880289133626132],\n",
       " ['mnb', 0.8646073797222528, 0.8548972188633616, 0.85599538449456],\n",
       " ['gnb', 0.8477520061558755, 0.8366494448719358, 0.8386270079563098],\n",
       " ['bnb', 0.863031768714961, 0.8554468506100913, 0.8533585051561963],\n",
       " ['knn', 0.8492176908138214, 0.8169726283390129, 0.8096077424499635],\n",
       " ['dt', 0.8599538309332747, 0.8347806969330549, 0.8390660850968713],\n",
       " ['rf', 0.8251438203070609, 0.8124656480158294, 0.8041114849965867],\n",
       " ['abc', 0.8956798944707046, 0.8783115312740464, 0.8662187894568323]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dda8bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Write target data to preds folder\n",
    "pd.DataFrame(y_test).to_csv('../preds/y_test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
